{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, Dropout\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (25000,) - y_train: (25000,)  X_test:(25000,) - y_test:(25000,)\n"
     ]
    }
   ],
   "source": [
    "## Load the IMDB dataset\n",
    "\n",
    "vocab_size = 10000\n",
    "(X_train,y_train), (X_test,y_test) = imdb.load_data(num_words=vocab_size)\n",
    "print(f'X_train: {X_train.shape} - y_train: {y_train.shape}  X_test:{X_test.shape} - y_test:{y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "14\n",
      "47\n",
      "8\n",
      "30\n",
      "31\n",
      "7\n",
      "4\n",
      "249\n",
      "108\n",
      "7\n",
      "4\n",
      "5974\n",
      "54\n",
      "61\n",
      "369\n",
      "13\n",
      "71\n",
      "149\n",
      "14\n",
      "22\n",
      "112\n",
      "4\n",
      "2401\n",
      "311\n",
      "12\n",
      "16\n",
      "3711\n",
      "33\n",
      "75\n",
      "43\n",
      "1829\n",
      "296\n",
      "4\n",
      "86\n",
      "320\n",
      "35\n",
      "534\n",
      "19\n",
      "263\n",
      "4821\n",
      "1301\n",
      "4\n",
      "1873\n",
      "33\n",
      "89\n",
      "78\n",
      "12\n",
      "66\n",
      "16\n",
      "4\n",
      "360\n",
      "7\n",
      "4\n",
      "58\n",
      "316\n",
      "334\n",
      "11\n",
      "4\n",
      "1716\n",
      "43\n",
      "645\n",
      "662\n",
      "8\n",
      "257\n",
      "85\n",
      "1200\n",
      "42\n",
      "1228\n",
      "2578\n",
      "83\n",
      "68\n",
      "3912\n",
      "15\n",
      "36\n",
      "165\n",
      "1539\n",
      "278\n",
      "36\n",
      "69\n",
      "2\n",
      "780\n",
      "8\n",
      "106\n",
      "14\n",
      "6905\n",
      "1338\n",
      "18\n",
      "6\n",
      "22\n",
      "12\n",
      "215\n",
      "28\n",
      "610\n",
      "40\n",
      "6\n",
      "87\n",
      "326\n",
      "23\n",
      "2300\n",
      "21\n",
      "23\n",
      "22\n",
      "12\n",
      "272\n",
      "40\n",
      "57\n",
      "31\n",
      "11\n",
      "4\n",
      "22\n",
      "47\n",
      "6\n",
      "2307\n",
      "51\n",
      "9\n",
      "170\n",
      "23\n",
      "595\n",
      "116\n",
      "595\n",
      "1352\n",
      "13\n",
      "191\n",
      "79\n",
      "638\n",
      "89\n",
      "2\n",
      "14\n",
      "9\n",
      "8\n",
      "106\n",
      "607\n",
      "624\n",
      "35\n",
      "534\n",
      "6\n",
      "227\n",
      "7\n",
      "129\n",
      "113\n"
     ]
    }
   ],
   "source": [
    "#Review X_train \n",
    "\n",
    "sample_review = X_train[0]\n",
    "sample_review\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train[0] decoded review: <UNK> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n"
     ]
    }
   ],
   "source": [
    "# Mapping of word index back to words\n",
    "\n",
    "word_to_index = imdb.get_word_index() # Returns all the word to index dict of vocab\n",
    "\n",
    "index_to_word = {index+3:word for word,index in word_to_index.items()} #Reversing the word to index - index to word\n",
    "\n",
    "\n",
    "''' \n",
    "Why add + 3 to the index?\n",
    "\n",
    "imdb.get_word_index() does not account for the reserved indices for \n",
    "special tokens (<PAD>, <START>, <UNK>, <UNUSED>). \n",
    "\n",
    "When loading the dataset using imdb.load_data, the data is preprocessed to include reserved tokens:\n",
    "0 for <PAD>: Used for padding sequences to the same length.\n",
    "1 for <START>: Marks the beginning of a review.\n",
    "2 for <UNK>: Replaces words that are not in the top num_words most frequent words.\n",
    "3 for <UNUSED>: Reserved for future use.\n",
    "\n",
    "As a result, the indices in the reviews (e.g., X_train, X_test) \n",
    "start from 4, and the word indices need to align accordingly.\n",
    "\n",
    "'''\n",
    "# Decode X_train[item]-> word indices to words\n",
    "\n",
    "def decode_review(review_index=0):\n",
    "    \"\"\"\n",
    "    Decodes a review from the IMDB dataset using index_to_word mapping.\n",
    "\n",
    "    Args:\n",
    "        review_index (int): The index of the review in X_train to decode. Defaults to 0.\n",
    "\n",
    "    Returns:\n",
    "        str: The decoded review as a string of words.\n",
    "    \"\"\"\n",
    "    return \" \".join(index_to_word.get(index, '<UNK>') for index in X_train[review_index])\n",
    "\n",
    "# Example usage\n",
    "item = 0\n",
    "print(f\"X_train[{item}] decoded review: {decode_review(item)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nBy default it takes 'pre' padding\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Padding the each item in X_train and X_test to have max length\n",
    "\n",
    "X_train = sequence.pad_sequences(X_train,maxlen=500)\n",
    "X_test = sequence.pad_sequences(X_test,maxlen=500)\n",
    "\n",
    "'''\n",
    "By default it takes 'pre' padding\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vjoseph\\OneDrive - FactSet\\Documents\\AI_Projects\\RNN -TextClassification\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Train Simple RNN\n",
    "\n",
    "# Initialize the model\n",
    "model = Sequential()\n",
    "\n",
    "# Embedding layer: Converts integer indices into dense vectors of fixed size (128)\n",
    "model.add(Embedding(vocab_size, 128, input_length=500))\n",
    "\n",
    "# SimpleRNN layer: RNN with 128 neurons\n",
    "model.add(SimpleRNN(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "\n",
    "# Dropout Layer for Regularization\n",
    "model.add(Dropout(0.2)) # 20% Dropout rate\n",
    "\n",
    "# Dense output layer with a single neuron (for binary classification)\n",
    "model.add(Dense(1, activation='sigmoid', kernel_regularizer=regularizers.l2(0.001)))\n",
    "\n",
    "# Build the model with the input shape\n",
    "model.build(input_shape=(None, 500))  # The input shape should match the shape of the training data\n",
    "\n",
    "optimizer = Adam(learning_rate = 1e-4)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss ='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m1,280,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,313,025</span> (5.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,313,025\u001b[0m (5.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,313,025</span> (5.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,313,025\u001b[0m (5.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.early_stopping.EarlyStopping at 0x1b696ca51c0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Setting up EarlyStopping\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss',patience=2,restore_best_weights=True)\n",
    "\n",
    "early_stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 55ms/step - accuracy: 0.5307 - loss: 0.8030 - val_accuracy: 0.5946 - val_loss: 0.7339\n",
      "Epoch 2/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 50ms/step - accuracy: 0.6835 - loss: 0.6771 - val_accuracy: 0.8562 - val_loss: 0.4163\n",
      "Epoch 3/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 53ms/step - accuracy: 0.8704 - loss: 0.3821 - val_accuracy: 0.8764 - val_loss: 0.3506\n",
      "Epoch 4/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 48ms/step - accuracy: 0.9081 - loss: 0.2891 - val_accuracy: 0.8630 - val_loss: 0.3658\n",
      "Epoch 5/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 49ms/step - accuracy: 0.9226 - loss: 0.2549 - val_accuracy: 0.8882 - val_loss: 0.3289\n",
      "Epoch 6/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 48ms/step - accuracy: 0.8984 - loss: 0.3134 - val_accuracy: 0.8904 - val_loss: 0.3310\n",
      "Epoch 7/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 50ms/step - accuracy: 0.9493 - loss: 0.1924 - val_accuracy: 0.8862 - val_loss: 0.3358\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1b6feb0cad0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Traing the Model with EarlyStopping\n",
    "\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=10,\n",
    "          batch_size=32,\n",
    "          validation_split =0.2,\n",
    "          callbacks=[early_stopping]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save the model file\n",
    "\n",
    "model.save('rnn_imdb.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
